%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Harvard ALM Thesis
%
% Author: Tony Allen (cyril0allen@gmail.com)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage{setspace,caption}
\doublespacing


% Default margins are too wide all the way around. I reset them here
\setlength{\topmargin}{1in}
\setlength{\textheight}{7in}
\doublespacing

\begin{document}
\author{Cyril Allen\\
Harvard Extension School}
\renewcommand{\today}{who knows}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}

% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

With the advent of cloud computing, datacenters are making use of distributed
applications more than ever. Companies like Google use software such as
MapReduce to generate over 20 petabytes of data per day using very large
numbers of commodity servers [3]. Many other companies use large scale clusters
to perform various computational tasks via the the open-source MapReduce
implementation, Hadoop [4], or they can possess a virtualized datacenter
allowing them to migrate virtual machines between various machines for
high-availability reasons. As economics change for hardware, it is likely that
a scalable cloud will have the requirement to mix node types, which will lead
to higher performance/capacity nodes being mixed with lower
performance/capacity HDD nodes. This thesis presents an adaptive data placement
method in the Nutanix distributed file system (ADSF) which will attempt to
remedy the common problems found in many heterogeneous clustered file systems.

  \subsection{Motivation}

  A number of scenarios arise in heterogeneous Nutanix clusters that can
  degrade performance for an entire cluster. The currently replica disk
  selection logic in Stargate uses does not take into account a number of
  variables such as disparities in tier size, CPU power, workloads, and disk
  health among other things.

  Considering that a write is not complete until all replicas are written, the
  write's performance is at the mercy of the slowest disk and node.  There are
  several scenarios, both pathological and daily occurences, where a more
  robust replica placement heuristic is required. For the work in this thesis,
  I will focus on two orthogonal cases described below.

    \subsubsection{Interfering Workloads}

    An example of interfering workloads can take the form of a 3-node
    homogeneous cluster with only 2 nodes hosting active workloads as shown in
    Figure \ref{fig:workload_disparity}. In the current random selection scheme
    in use by the ADSF, writes are equally likely to place their replica on the
    other node with an active workload as they would be to place it on the idle
    node. This can impact performance on both the local and remote workloads as
    secondary writes will be slower on nodes whose resources are being utilized
    by their primary workloads. An adaptive replica placement scheme is needed
    to avoid the busy node and bias secondary replica placement on an idle
    node. 

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.4]{images/homogeneous_workload_disparity.pdf} 
      \caption{A cluster with identical nodes running a heterogeneous workload.}
      \label{fig:workload_disparity}
    \end{figure}

    \subsubsection{Nodes with Tier Size Disparities}

    A cluster containing nodes with a tier size disparity are susceptible to a
    skew in node fullness, even if the workload on each node is identical. This
    can be illustrated via Figure \ref{fig:tier_size_disparity} where we have a
    3-node heterogeneous cluster with 2 high-end nodes and a single weak node.
    Suppose these high-end nodes have 500GB of SSD tier and 6TB of HDD tier and
    the single weak node has only 128GB of SSD tier and 1TB of HDD tier. If 3
    simultaneous workloads were to generate data such that the working sets of
    the workloads are 50\% of the local SSD tier, the weaker node is at a
    significant disadvantage. Given the current NDFS replica selection
    algorithm, we can expect 500GB of replica traffic to flood the weak node
    and fill up its SSD tier well before the workload is finished. This results
    in an inability for the workload on the smaller node to place its primary
    replicas locally and forces the workload to rely on remote CVMs, increasing
    latency. An adaptive replica placement heuristic would mitigate this issue
    by taking disk usages into consideration during the placement of secondary
    replicas and biasing placement of secondary replicas on the nodes with more
    free capacity.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.4]{images/homogeneous_tier_disparity.pdf} 
      \caption{A cluster with nodes of varying resource capacity.}
      \label{fig:tier_size_disparity}
    \end{figure}

  \subsection{Acropolis Base System}

  NDFS is facilitated by a clustering of controller virtual machines (CVMs)
  which reside, one per node, on each server in the cluster. The CVM presents
  via NFS (for VMWare's ESXi [14]), SMB (for Microsoft's Hyper-V [17]), or
  iSCSI (for Nutanix's AHV [1]) an interface to each hypervisor that they
  reside on. For example, the interface provided by the CVMs to VMware's ESXi
  hypervisor [14] will be interfaced with as a datastore. The virtual machines'
  virtual disk files will reside on the Nutanix datastore and be accessed via
  NFS through the CVM sharing a host with the user VM. Within the CVM exists an
  ecosystem of process that make up the ADSF. This work is scoped specifically
  to the I/O manager process, Stargate.


  \subsection{Stargate}

  The Stargate process is responsible for all data management and I/O
  operations. The NFS/SMB/iSCSI interface presented to the hypervisor is also
  presented by Stargate. All file allocations and data replica placement
  decisions are made by this process.

  As the Stargate process facilitates writes to physical disks, it gathers
  statistics for each disk such as the number of operations currently in flight
  on the disk (queue length), how much data in bytes currently resides on the
  disk, and average time to complete an operation on the disk. These statistics
  are only gathered on the local disks; however, they are then stored in a
  distributed database provided by another ADSF service along with the
  statistics gathered by every other Stargate in the cluster. These disk
  statistics stored in the database and are pulled periodically and are then
  used to make decisions on data placement when performing writes.

    \subsubsection{Oplog and Extent Store}

% TODO

    \subsubsection{Arithmos Interactions}

% TODO

    \subsubsection{Storage Tiering}

% TODO

    \subsubsection{Data Replication and Fault Tolerance}

% TODO

    \subsubsection{Replica Selection}

% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Prior Work}

% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation}

  \subsection{Stargate Disk Stats Collection}

  Prior to this work, Stargate's periodic disk stats collection was limited to
  caching solely disk usage stats for all disks in the cluster.  This has been
  expanded to now include disk performance stats for use in disk fitness
  values.

  Stargate maintains a mapping, henceforth referred to as the $disk\_map\_$,
  from cluster disk ID to a disk state structure. The $disk\_map\_$'s state
  structure contains disk usage and performance information that has been
  published to Arithmos by other Stargates in the cluster. Upon gathering fresh
  stats from Arithmos, the information is used to create a disk fitness value
  for each disk in the cluster.

  \subsection{Fitness Values and Functions}

  To calculate a value to represent the desirability of a disk for replica
  placement, we'll use a function, $f_{fitness}$ that takes as its argument
  disk stats and returns a positive number we will call a fitness value. A low
  fitness value indicates a poor placement candidacy for a disk and a high
  fitness value will indicate a highly desirable disk for replica placement. In
  this thesis, I evaluate two fitness functions that are comprised of terms
  that utilize a disk's average queue length over some stretch of time,
  $t_{q}$, and a disk's percentage utilization, $t_{u}$.

  \begin{equation}
    t_{q} = 1 - \frac{q}{q_{ceil}}
  \end{equation}

  $q_{ceiling}$ is defined as the maximum observed queue length such that
  beyond this value, $t_{q}$ does not contribute to the fitness
  value. This ensures that as the queue length grows, $t_{q}$
  approaches zero. 

  \begin{equation}
    t_{u} = \frac{1}{a^{u}}
  \end{equation}

  $u$ is the disk utilization percentage and $a$ is an aggression variable used
  to control the exponential decay of $t_{u}$. The larger $a$ is, the
  more aggressively $t_{u}$ will decay as $u$ increases. An
  aggressive decay results in more preference given to less utilized disks when
  compared with disks that are slightly more utilized.

  These terms are used in two different fitness functions evaluated in this
  thesis:

  \begin{equation}
    f_{add} = t_{u} + t_{q}
  \end{equation}

  \begin{equation}
    f_{mult} = t_{u}t_{q}
  \end{equation}


  \subsection{Weighted Random Selection Algorithms}

  After a weight is calculated for a disk in the cluster that will store a
  replica, the WeightedVector class' Sample() calls will perform a weighted
  random selection on the set of potential candidate disks. To determine the
  best method of weighted random selection for Stargate's WeightedVector class,
  an exploration of various weighted random selection algorithms was necessary.
  Since the file system only supports replication factors of 2 or 3, the
  investigation was limited to algorithms that allow for a weighted $N$ choose
  $Y$, where $Y$ is the data replication factor.

  This section provides an overview of the algorithms investigated via
  simulations to compare each algorithm at different orders of magnitude.

    \subsubsection{Scalability Simulation Methodology}
     To test the scalability of the weighted random selection algorithms
     evaluated in the next section, a single-threaded Python script was written
     to to evaluate the change in run time as sample sets increase. Each
     algorithm's time to select is calculated for each of a fixed number of
     iterations for multiple sample sets. pseudo-code for the simulations
     can be written as follows:

     \begin{verbatim}
     for each selection_algorithm in algorithm_list:
         run_time_values = empty_list()
         for each sample_set_size in all_sample_set_sizes:
             sample_set = generate_sample_set(sample_set_size)
             all_elapsed_times = empty_list()
             for each iteration:
                 start_time = time.now()
                 selection_algorithm(sample_set)
                 elapsed_time = time.now() - start_time
                 all_elapsed_times.append(elapsed_time)
             calculate_avg_elapsed_time(all_elapsed_times)
             calculate_std_error(all_elapsed_times)
     \end{verbatim}
        
    Object weights are constant throughout the simulation, so selection schemes
    that require some amount of preprocessing (such as the top T\% calculation
    for truncation selection) are performing their preprocessing steps for each
    selection. This gives information about the worst-case behavior for each
    algorithm in comparison with others'.

    \subsubsection{Herding Behavior Evaluation Methodology}
    Herding behaviors can be seen in some weighted random selection
    algorithms when (TODO: cite some papers) the weights of a subset of objects
    in the sampling pool cause a disproportionate amount of selections to
    target those objects. In the case of replica disk selections in a Nutanix
    cluster, this can cause too many operations to target an especially
    suitable disk, resulting in poor performance. We can simulate an
    exaggerated scenario in which the susceptibility to herding behavior can be
    observed by having a single object with a weight that is multiple orders of
    magnitude heavier than the next highest object in the sampling set. It is
    also necessary to observe any herding behavior for a sampling set with low
    weight skew. This section describes the simulation methodology for each.

    High-skew sampling sets of 11 objects were generated such that the array
    index of the first 10 objects was assigned as the object weight, and the
    last object was given a weight of 1000. This creates an extremely large
    skew in weights and makes the high-weight object a target for herding
    behavior. Given this sampling set, weighted random selections were
    performed and a histogram was kept that tracked the number of selections
    for each object. 1e3, 1e4, and 1e5 iterations were performed to observe any
    changes in herding behavior at larger time scales. In addition to the
    high-skew sampling sets, low-skew sets of 100 objects were also simulated.
    These low-skew sets were identical to the high-skew sets, except there was
    not a single object with an exaggerated weight of 1000. All element weights
    were their array indices.

    \subsubsection{Stochastic Universal Sampling (SUS) Simulations}
    SUS is another sampling technique first introduced by Baker in 1987 [10].
    The algorithm can be understood as follows: On a standard roulette wheel
    there's a single pointer that indicates the winner. The roulette wheel's
    "bins" can all be the same size which would indicate a uniform probability
    of selecting any bin and could also be unevenly sized which would indicate
    a weighted probability. SUS uses this same concept except allows for N
    evenly spaced pointers corresponding to the selection of N items. Key
    things to note are that the set, or "bins" in my roulette analogy, must be
    shuffled prior to selection. Also, there is a minimum spacing allowed for
    the pointers to prevent selection of the same bin.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/herding_roullette.png} 
      \caption{Histograms generated by simulation of Stochastic Universal
               Sampling using sample sizes of 1e3, 1e4, and 1e5. Object weights
               for the histograms are in the range [1,100].}
      \label{fig:herding_roullette}
    \end{figure}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/pathological_roullette.png} 
      \caption{Histograms generated by simulation of Stochastic Universal
               Sampling using sample sizes of 1e3, 1e4, and 1e5. Object weights
               are in the range [0,9] with a single outlier of weight 1000 to
               illustrate the effect of herding behavior.}
      \label{fig:pathological_roullette}
    \end{figure}

    Figure \ref{fig:herding_roullette} shows the evolution of the
    distribution of selection frequencies for SUS as the number of samples
    increases. We can see that the selection frequency is proportional to the
    object weight. This can prove problematic for outlier objects with weights
    that are much larger than the other objects in the set as shown in Figure
    \ref{fig:pathological_roullette}. We can see that the high weight object's
    selection frequency eclipses all other objects in the selection pool which
    can lead to extreme herding behaviors.

    \subsubsection{Tructation Selection Simulations}
    Truncation selection[TODO: CITE] does not consider any objects for
    selection below some threshold, $T$. In figure
    \ref{fig:herding_truncation}, only the top 10\% of objects ranked by weight
    are considered for selection. Within this subset, weight has no meaning so
    there is a uniform distribution of selections. However, this may not be
    suitable for use cases where all objects must be candidates for selection.
    Depending on the threshold chosen, this algorithm can be resistant to
    herding behavior as shown in Figure \ref{fig:pathological_truncation}. 

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/herding_truncation.png} 
      \caption{Histograms generated by simulation of truncation selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights
               for the histograms are in the range [1,100].}
      \label{fig:herding_truncation}
    \end{figure}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/pathological_truncation.png} 
      \caption{Histograms generated by simulation of truncation selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights are in
               the range [0,9] with a single outlier of weight 1000 to
               illustrate the effect of herding behavior.}
      \label{fig:pathological_truncation}
    \end{figure}

    \subsubsection{Two-choice Sampling Simulations}
    Two-choice sampling, first introduced by %TODO: mitzenmacher paper
    has proven to be extremely resilient to herding behavior as shown in
    Figure \ref{fig:pathological_two_choice} and selection frequencies for all
    objects are influenced by object weights in a way similar to SUS. While an
    object with a higher weight is more likely to be selected, it is not
    selected with a probability proportional to its fitness value. This makes
    the algorithm resistant to any herding behaviors, but will not be a good
    candidate if we desire the WeightedVector to select objects with
    probability proportional to its weight.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/herding_two_choice.png} 
      \caption{Histograms generated by simulation of two-choice selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights
               for the histograms are in the range [1,100].}
      \label{fig:herding_two_choice}
    \end{figure}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/pathological_two_choice.png} 
      \caption{Histograms generated by simulation of two-choice selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights are in
               the range [0,9] with a single outlier of weight 1000 to
               illustrate the effect of herding behavior.}
      \label{fig:pathological_two_choice}
    \end{figure}

    \subsubsection{Uniform Random Selection Simulations}
    Uniform random selection is completely indifferent to object weights.
    Therefore, it exhibits no herding behavior and no usefulness for the
    WeightedVector's sampling, but it is important to include its analysis for
    comparison with other selection algorithms.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/herding_random.png} 
      \caption{Histograms generated by simulation of uniform random selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights
               for the histograms are in the range [1,100].}
      \label{fig:herding_random}
    \end{figure}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/pathological_random.png} 
      \caption{Histograms generated by simulation of uniform random selection
               using sample sizes of 1e3, 1e4, and 1e5. Object weights are in
               the range [0,9] with a single outlier of weight 1000 to
               illustrate the effect of herding behavior.}
      \label{fig:pathological_random}
    \end{figure}

    Figure \ref{fig:pathological_truncation} shows that we can expect uniform
    selection probabilities and Figure \ref{fig:pathological_random} confirms
    that we can expect no herding behavior with a uniform random selection
    scheme.

    \subsubsection{Weighted Random Algorithm Scalability Simulations}
    It's clearly seen that even though both SUS and truncation selection are
    [TODO: cite runtimes for each]
    exponential in run time, truncation selection is slower than SUS by an
    order of magnitude. This is mainly due to the need for the truncation
    selection algorithm to calculate the top T\% of the set for every selection
    performed. As expected, two-choice and random selections are
    observed to be constant-time algorithms. Two-choice is slightly slower than
    random selection due to the second selection and comparison operation that
    must occur.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.25]{images/random_scalability.png} 
      \caption{Running times of various weight random selection algorithms.
               Each algorithm is run for 10 iterations at each object pool
               size.}
      \label{fig:random_scalability}
    \end{figure}

  \subsection{WeightedVector Class}

  % TODO: Fix the code spacing.

  It's necessary to perform repeated weighted sampling of disk IDs, easily, and
  given their fitness values. An object container class is needed similar to a
  C++ STL container [XXX CITE XXX] that can also access elements of arbitrary
  types via arbitrary weighted random sampling methods. The WeightedVector
  class was implemented to fulfill this requirement. 

  Upon instantiation of the WeightedVector class, a fitness function is
  provided to store the fitness values of all objects internally. The
  WeightedVector class has implemented insertion, removal, and weighted random
  sampling of objects of some arbitrary type, $T$, based on the object's
  fitness value as a weight.

  The set of objects and their fitness values are stored in $std::vector$
  objects , one for the object references stored in the WeightedVector and one
  for their corresponding fitness values. The objects and their corresponding
  fitness values share an index into their respective internal vectors.

    \subsubsection{Public Interface}

     \begin{verbatim}
       WeightedVector(const std::function<double(const T)>)
     \end{verbatim}

     The WeightedVector class is instantiated by providing a fitness function
     that accepts a reference to an object of type \emph{T} and returns a
     fitness value that is of type \emph{double}. The provided fitness function
     is used to create a mapping between inserted objects and their
     corresponding fitness values for sampling.

     The WeightedVector class asserts that the fitness function returns positive
     values.

     \begin{verbatim}
       void EmplaceBack(const T& element)
     \end{verbatim}

     The EmplaceBack function constructs and inserts an object of type
     \emph{T} at the end of the vector. This increases the WeightedVector's
     size by 1.

     \begin{verbatim}
       bool Empty()
     \end{verbatim}

     Returns true if the WeightedVector is of size 0.

     \begin{verbatim}
       void Clear()
     \end{verbatim}

     Resets all state in the WeightedVector object, sets the size to 0, and
     clears all internal vectors.

     \begin{verbatim}
       T& Sample()
     \end{verbatim}

     Returns a reference to an object stored inside of the WeightedVector.
     Objects are sampled via weighted random selection and subsequent calls to
     Sample are guaranteed not to return the same object unless Reset is called
     before sampling again. The WeightedVector class asserts that Sample is not
     called more times than the size of the WeightedVector.

     \begin{verbatim}
       void Reset()
     \end{verbatim}

     Resets the sampling state of the WeightedVector, allowing sampled objects
     to be eligible for selection in subsequent Sample calls.

     \begin{verbatim}
       size_t size()
     \end{verbatim}

     Returns the size of the WeightedVector.

    \subsubsection{Weighted Vector Internals}

    Internally, the WeightedVector class keeps 3 different std:vector objects
    to keep track of sampling state and the object-to-fitness value mapping.
    There is the inner\_vector\_ variable which stores the objects
    inserted via EmplaceBack(), the weights\_ variable which stores the
    fitness values of all objects in the inner\_vector\_, and the
    sampling\_weights\_ variable which is identical to weights\_
    except that objects weights are set to 0 when sampled. This allows us to
    exclude objects from being sampled multiple times with time complexity
    $O(1)$, since a weight of 0 gives a probability of 0 for sampling using
    Stochastic Universal Sampling as shown in the example below.

    Before sampling, we have identical weights\_ and sampling\_weights\_
    accompanying an inner\_vector\_ of objects:

    \begin{center}
      \begin{tabular}{ | l | c | c | c | r | }
        \hline
        \verb|inner_vector_| & $A$ & $B$ & $C$ & $D$ \\ \hline
        \verb|weights_| & 1 & 3 & 3 & 7 \\ \hline
        \verb|sampling_weights_| & 1 & 3 & 3 & 7 \\ \hline
        \hline
      \end{tabular}
    \end{center}

    Suppose we then call Sample() on the WeightedVector and it returns $D$. The
    probability of this event is 0.5, so to maintain sampling state within the
    WeightedVector, the weight associated with object $D$ is set to zero:

    \begin{center}
      \begin{tabular}{ | l | c | c | c | r | }
        \hline
        \verb|inner_vector_| & $A$ & $B$ & $C$ & $D$ \\ \hline
        \verb|weights_| & 1 & 3 & 3 & 7 \\ \hline
        \verb|sampling_weights_| & 1 & 3 & 3 & 0 \\ \hline
        \hline
      \end{tabular}
    \end{center}

    If we call Sample() again, it is not possible to return $D$ since its
    sampling weight is now zero. The probabilities of returning $A$, $B$, or
    $C$ in subsequent calls to Sample() are $\frac{1}{7}$, $\frac{3}{7}$, and
    $\frac{3}{7}$ respectively. Suppose two more calls to Sample() lead to the
    following state:

    \begin{center}
      \begin{tabular}{ | l | c | c | c | r | }
        \hline
        \verb|inner_vector_| & $A$ & $B$ & $C$ & $D$ \\ \hline
        \verb|weights_| & 1 & 3 & 3 & 7 \\ \hline
        \verb|sampling_weights_| & 0 & 3 & 0 & 0 \\ \hline
        \hline
      \end{tabular}
    \end{center}

    We may only call Sample() one more time without triggering an assertion
    failure and the WeightedVector is obligated to return $D$. The only way to
    restore sampling state is to call Reset(). A Reset call simply copies
    weights\_ into sampling\_weights\_ and all objects are eligible for
    sampling again:

    \begin{center}
      \begin{tabular}{ | l | c | c | c | r | }
        \hline
        \verb|inner_vector_| & $A$ & $B$ & $C$ & $D$ \\ \hline
        \verb|weights_| & 1 & 3 & 3 & 7 \\ \hline
        \verb|sampling_weights_| & 1 & 3 & 3 & 7 \\ \hline
        \hline
      \end{tabular}
    \end{center}


    \subsubsection{Weighted Vector Unit Testing}

    The WeightedVector class' unit test has four phases:

    \begin{enumerate}
      \item Testing Average() functionality
      \item Testing there are no duplicate samples
      \item Testing sampling with uniform probabilities
      \item Testing sampling with non-uniform probabilities
    \end{enumerate}
    
all start by defining a fitness
    function unique to each phase of the test:
    
    
    The expected probability of each object is
    then calculated prior to the test. For example, a fitness function that
    just returns a uniform random number as the value would warrant an expected
    probability inversely proportional to num\_elements for each element.
    Elements are then sampled for a number of times several orders of magnitude
    larger than the number of elements. Each sampled element's number of times
    being selected is tracked in a test-local map. We then calculate the actual
    selection probability of each element in the WeightedVector with the
    expected value and verify the difference is within an acceptable tolerance.
      
  \subsection{Replica Selection Unit Testing}

% TODO

    \subsubsection{WeightedVector Unit Tests}

% TODO

    \subsubsection{ReplicaSelector Unit Tests}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation and Results}

The experiments below seek to measure the effect of the additive and
multiplicative term fitness functions on both the tier utilization of each node
and the queue lengths of disks residing on those nodes compared with uniform
random selection.

  \subsection{Experimental Setup}

  The replica selection schemes were evaluated using a NX-1350 for evaluating
  the disk fullness and a NX-3-node cluster). Each node contains a single 300GB
  SSD and 4 HDDs 1TB in size. When evaluating the new replica disk selection
  framework, two heterogeneous workload scenarios are tested:
 
  \begin{enumerate}
    \item Two worker VMs on separate nodes running a workload with low
          outstanding ops.
    \item Two worker VMs on separate nodes with running a
          workload with high outstanding ops.
  \end{enumerate}
 
  \subsection{Fio and Write Patterns}

  When generating I/O in these experiments, Fio is used on the worker VMs. Fio,
  short for Flexible IO, is an I/O workload generator that can take
  configuration files to specify the parameters of a test. On each worker VM,
  fio is used to generate a sequential write workload that completely fills the
  cluster's hot-tier. I choose to use exclusively sequential writes for all
  tests because they are the default for fio tests and the purpose of these
  experiments is to generate new replicas in a consistent manner. For the
  purposes of replica placement, the Nutanix file system does not distinguish
  targets based on the write pattern that generatred an extent group.

  \subsection{Tier Utilization Experiments}

  The tier utilization experiments define the hot-tier deviation,
  $d_{hot tier}$, as the average SSD utilization percentage of the nodes
  running a workload, $u_{w}$, subtracted by the SSD utilization percentage of
  the node without a workload, $u_{o}$:
  
  \begin{equation}
    d_{hot\ tier} = \frac{u_{w1} + u_{w2}}{u_{o}}
  \end{equation}
  
  Ideally, the idle node would absorb the majority of secondary replicas from
  the running workloads. However, uniform random selection causes only 50\% of
  secondary replicas to go to the idle node even though it can potentially
  handle more work due to the fact that it does not have to service a local
  workload. In a uniform random replica selection scheme, we expect the
  nodes running a workload have to bear 100\% of their own primary replicas and
  50\% of secondary replicas from the other worker node. This causes total SSD
  utilization to be skewed towards the worker nodes and for this skew to grow
  as the tests run. This is indicated by higher $d_{hot\ tier}$ values. We
  expect a more sophisticated replica selection scheme to minimize
  $d_{hot\ tier}$ by biasing secondary replicas towards the idle node and
  limiting the skew.

  % TODO: should I include fio scripts here, in some appendix, or in the user
  % guide?

    \subsubsection{Low Outstanding Operation Results}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/low_outstanding_exp.png} 
      \caption{$d_{hot\ tier}$ values over time for low outstanding I/O
               operations.}
      \label{fig:low_outstanding_tier_disparity}
    \end{figure}

    Figure \ref{fig:low_outstanding_tier_disparity} shows the results of a
    workload with only a single outstanding operation. This causes the queue
    length reported by Stargate to be at most 1, resulting in the fitness
    function's queue length term to be roughly constant and approximately 1.
    
    We can see that the additive fitness function does not minimize the
    hot-tier deviation as well as the multiplicative. This is because an
    additive fitness function's behavior varies depending on the weight chosen
    for the queue length term. By default, the linear fitness function
    gives equal weight to both the disk fullness and queue length terms;
    however, for one run of this experiment the queue length term was given no
    weight. Linear fitness that gives equal weight to both terms does not
    reduce skew by very much while giving no weight to the queue length term
    keeps all nodes' usages within 10\% of each other. This is because the
    queue length term is contributing the maximum amount possible to the
    fitness value due to the consistently low queue length values. We can
    illustrate this by defining a disk selection bias, $b_r$, as the
    probability some disk, $d$, will be selected when compared with another
    disk, $d'$ whose utilization is 10\% higher and queue length value is
    identical. Given a fitness function, $f$, we can calculate $b_r$ as
    follows:

    \begin{equation}
      b_r = \frac{f(d)}{f(d) + f(d')}
    \end{equation}

    Figures \ref{fig:bias_max_qlen} and \ref{fig:bias_min_qlen} show the disk
    selection biases for very large and very small queue lengths respectively.

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/replica_selection_bias_max_qlen.png} 
      \caption{$b_r$ values with static queue lengths at the fitness
               function ceiling values.}
      \label{fig:bias_max_qlen}
    \end{figure}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/replica_selection_bias_min_qlen.png} 
      \caption{$b_r$ values with static queue lengths at 1.}
      \label{fig:bias_min_qlen}
    \end{figure}

    We can see that for an additive fitness function, the bias towards a less
    utilized disk decreases as the disk fullness percentages for $d$ and $d'$
    increase, even though they still only differ by 10\% in the figure above.
    This is because the entire linear fitness function does not scale with each
    term, so we can conclude that the multiplicative fitness function is
    superior.

    \subsubsection{High Outstanding Operation Results}

    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.30]{images/high_outstanding_exp.png} 
      \caption{$d_{hot\ tier}$ values over time for low outstanding I/O
               operations.}
      \label{fig:high_outstanding_tier_disparity}
    \end{figure}


    In Figure \ref{fig:high_outstanding_tier_disparity}, we can see that both
    additive and multiplicative fitness functions reduce the disk fullness skew
    from 30\% to less than 10\%. Multiplicative fitness performs slightly
    better at minimizing $d_{hot\ tier}$ than additive fitness, possibly due to
    scaling the fitness value by the value of both the fullness and queue
    length terms, rather than weights.
  
  \subsection{Disk Queue Length Experiments}

  Since a low outstanding operation workload would not give useful
  information for measuring the effects of fitness-based replica selection on
  disk queue lengths, the high outstanding I/O operation experiment in the
  previous section was re-run for all fitness function types and for fitness
  function queue length term ceilings of 200 and 100. Figures
  \ref{fig:qlen_100} and \ref{fig:qlen_200} show a reduction in
  queue length quartiles when fitness-based selection is used for disks on
  nodes that host local workloads. Lower queue length ceilings are
  observed to provide better results in reducing the queue lengths for the
  worker nodes.

  \begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.30]{images/qlen_100_box.png} 
    \caption{Queue lengths for all SSDs on the specified nodes sampled every 1
             second.}
    \label{fig:qlen_100}
  \end{figure}

  \begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.30]{images/qlen_200_box.png} 
    \caption{Queue lengths for all SSDs on the specified nodes sampled every 1
             second.}
    \label{fig:qlen_200}
  \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{User Guide}

% TODO

  \subsection{Re-creating Experiments}

% TODO

  \subsection{Scraping Data From the Nutanix Cluster}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

% TODO

  \subsection{Summary}

% TODO

    \subsubsection{Low Outstanding Operation Test}

% TODO

    \subsubsection{High Outstanding Operation Test}

  \subsection{Conclusion}

    % Explain how this work solves the stated problems.

% TODO

  \subsection{Future Work}

% TODO

    \subsubsection{Real-time Fitness Feedback}

      % Realtime feedback from disks using historical latency numbers.
    
% TODO

    \subsubsection{Read Replica Selection}

      % Based on historical latencies.

% TODO

    \subsubsection{More Fitness Function Variables}

      % CPU, disk wear, data access patterns.

% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Appendix}

% TODO

  \subsection{Herding Behavior Due to Implementation Bug}

% TODO

  \subsection{Glossary}

% TODO

  \subsection{References}

% TODO


\end{document}
